# -*- coding: utf-8 -*-
"""Unit Perceptron.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nhdnAnuxdgd9yAovdG43pUohycIMT7is
"""

import numpy as np

# Step activation function (binary step)
def step_function(x):
    return 1 if x >= 0 else 0

# Single unit perceptron class
class Perceptron:
    def __init__(self, input_size, learning_rate=0.1, epochs=100):
        self.weights = np.zeros(input_size)
        self.bias = 0
        self.learning_rate = learning_rate
        self.epochs = epochs

    def predict(self, x):
        linear_output = np.dot(x, self.weights) + self.bias
        return step_function(linear_output)

    def train(self, X, y):
        for epoch in range(self.epochs):
            for xi, target in zip(X, y):
                prediction = self.predict(xi)
                error = target - prediction
                # Update rule
                self.weights += self.learning_rate * error * xi
                self.bias += self.learning_rate * error

# Sample linearly separable dataset (AND logic gate)
X = np.array([[0,0], [0,1], [1,0], [1,1]])
y = np.array([0, 0, 0, 1])  # AND gate outputs

# Initialize Perceptron
perceptron = Perceptron(input_size=2, learning_rate=0.1, epochs=10)

# Train the perceptron
perceptron.train(X, y)

# Test predictions
print("Predictions:")
for x_test in X:
    print(f"Input: {x_test}, Predicted Output: {perceptron.predict(x_test)}")